{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiprocessing refers to the ability of a system to support more than one processor at the same time. Applications in a multiprocessing system are broken to smaller routines that run independently. The operating system allocates these threads to the processors improving performance of the system.\n",
    "\n",
    "<br>\n",
    "<font size=\"5\">OR</font>\n",
    "\n",
    "multiprocessing is a package that supports spawning processes using an API similar to the threading module. The multiprocessing package offers both local and remote concurrency, effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows.\n",
    "\n",
    "The multiprocessing module also introduces APIs which do not have analogs in the threading module. A prime example of this is the Pool object which offers a convenient means of parallelizing the execution of a function across multiple input values, distributing the input data across processes (data parallelism). The following example demonstrates the common practice of defining such functions in a module so that child processes can successfully import that module. This basic example of data parallelism using Pool,\n",
    "\n",
    "# Why MultiProcessing ?\n",
    "\n",
    "Consider a computer system with a single processor. If it is assigned several processes at the same time, it will have to interrupt each task and switch briefly to another, to keep all of the processes going.\n",
    "This situation is just like a chef working in a kitchen alone. He has to do several tasks like baking, stirring, kneading dough, etc.\n",
    "\n",
    "So the gist is that: The more tasks you must do at once, the more difficult it gets to keep track of them all, and keeping the timing right becomes more of a challenge.\n",
    "This is where the concept of multiprocessing arises!\n",
    "A multiprocessing system can have:\n",
    "\n",
    "multiprocessor, i.e. a computer with more than one central processor.\n",
    "multi-core processor, i.e. a single computing component with two or more independent actual processing units (called “cores”).\n",
    "Here, the CPU can easily executes several tasks at once, with each task using its own processor.\n",
    "\n",
    "It is just like the chef in last situation being assisted by his assistants. Now, they can divide the tasks among themselves and chef doesn’t need to switch between his tasks\n",
    "\n",
    "\n",
    "##  Threading vs. Processing\n",
    "\n",
    "A good illustration of threading vs. processing would be to download an image file and turn it into a thumbnail.\n",
    "\n",
    "The first part, communicating with an outside source to download a file, involves a thread. Once the file is obtained, the work of converting it involves a process. Essentially, two factors determine how long this will take; the input/output speed of the network communication, or I/O, and the available processor, or CPU.\n",
    "\n",
    "#### I/O-intensive processes improved with multithreading:\n",
    "* webscraping\n",
    "* reading and writing to files\n",
    "* sharing data between programs\n",
    "* network communications\n",
    "\n",
    "\n",
    "#### CPU-intensive processes improved with multiprocessing:\n",
    "* computations\n",
    "* text formatting\n",
    "* image rescaling\n",
    "* data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        print(p.map(f, [1, 2, 3])) #will print to standard output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing in Python\n",
    "\n",
    "In Python, the multiprocessing module includes a very simple and intuitive API for dividing work between multiple processes.\n",
    "Let us consider a simple example using multiprocessing module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the multiprocessing module \n",
    "import multiprocessing \n",
    "  \n",
    "def print_cube(num): \n",
    "    \"\"\" \n",
    "    function to print cube of given num \n",
    "    \"\"\"\n",
    "    print(\"Cube: {}\".format(num * num * num))   \n",
    "def print_square(num): \n",
    "    \"\"\" \n",
    "    function to print square of given num \n",
    "    \"\"\"\n",
    "    print(\"Square: {}\".format(num * num))   \n",
    "if __name__ == \"__main__\": \n",
    "    # creating processes \n",
    "    p1 = multiprocessing.Process(target=print_square, args=(10, )) \n",
    "    p2 = multiprocessing.Process(target=print_cube, args=(10, )) \n",
    "  \n",
    "    # starting process 1 \n",
    "    p1.start() \n",
    "    # starting process 2 \n",
    "    p2.start() \n",
    "  \n",
    "    # wait until process 1 is finished \n",
    "    p1.join() \n",
    "    # wait until process 2 is finished \n",
    "    p2.join() \n",
    "  \n",
    "    # both processes finished \n",
    "    print(\"Done!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Process class\n",
    "\n",
    "In multiprocessing, processes are spawned by creating a Process object and then calling its start() method. Process follows the API of threading.Thread. A trivial example of a multiprocess program is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "def f(name):\n",
    "    print('hello', name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Process(target=f, args=('bob',))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    \n",
    "#To show the individual process IDs involved, here is an expanded example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "def info(title):\n",
    "    print(title)\n",
    "    print('module name:', __name__)\n",
    "    print('parent process:', os.getppid())\n",
    "    print('process id:', os.getpid())\n",
    "\n",
    "def f(name):\n",
    "    info('function f')\n",
    "    print('hello', name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    info('main line')\n",
    "    p = Process(target=f, args=('bob',))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    \n",
    "#For an explanation of why the if __name__ == '__main__' part is necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contexts and start methods\n",
    " multiprocessing supports three ways to start a process. These start methods are\n",
    "\n",
    "spawn\n",
    "\n",
    "The parent process starts a fresh python interpreter process. The child process will only inherit those resources necessary to run the process objects run() method. In particular, unnecessary file descriptors and handles from the parent process will not be inherited. Starting a process using this method is rather slow compared to using fork or forkserver.\n",
    "\n",
    "Available on Unix and Windows. The default on Windows.\n",
    "\n",
    "fork\n",
    "\n",
    "The parent process uses os.fork() to fork the Python interpreter. The child process, when it begins, is effectively identical to the parent process. All resources of the parent are inherited by the child process. Note that safely forking a multithreaded process is problematic.\n",
    "\n",
    "Available on Unix only. The default on Unix.\n",
    "\n",
    "forkserver\n",
    "\n",
    "When the program starts and selects the forkserver start method, a server process is started. From then on, whenever a new process is needed, the parent process connects to the server and requests that it fork a new process. The fork server process is single threaded so it is safe for it to use os.fork(). No unnecessary resources are inherited.\n",
    "\n",
    "# Exchanging objects between processes\n",
    "\n",
    "multiprocessing supports two types of communication channel between processes:\n",
    "\n",
    "### Queues\n",
    "\n",
    "The Queue class is a near clone of queue.Queue. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def f(q):\n",
    "    q.put([42, None, 'hello'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    p = Process(target=f, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())    # prints \"[42, None, 'hello']\"\n",
    "    p.join()\n",
    "#Queues are thread and process safe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipes\n",
    "\n",
    "The Pipe() function returns a pair of connection objects connected by a pipe which by default is duplex (two-way). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=f, args=(child_conn,))\n",
    "    p.start()\n",
    "    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n",
    "    p.join()\n",
    "    \n",
    "#The two connection objects returned by Pipe() represent the two ends of the pipe.\n",
    "#Each connection object has send() and recv() methods (among others).\n",
    "#Note that data in a pipe may become corrupted\n",
    "#if two processes (or threads) try to read from or write to the same end of the pipe at the same time.\n",
    "#Of course there is no risk of corruption from processes using different ends of the pipe at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronization between processes\n",
    "\n",
    "multiprocessing contains equivalents of all the synchronization primitives from threading. For instance one can use a lock to ensure that only one process prints to standard output at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom multiprocessing import Process, Lock\n",
    "\n",
    "def f(l, i):\n",
    "    l.acquire()\n",
    "    try:\n",
    "        print('hello world', i)\n",
    "    finally:\n",
    "        l.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lock = Lock()\n",
    "\n",
    "    for num in range(10):\n",
    "        Process(target=f, args=(lock, num)).start()\n",
    "        \n",
    "# Without using the lock output from the different processes is liable to get all mixed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing state between processes\n",
    "\n",
    "### 1 Shared memory :\n",
    "\n",
    "As mentioned above, when doing concurrent programming it is usually best to avoid using shared state as far as possible. This is particularly true when using multiple processes.\n",
    "\n",
    "However, if you really do need to use some shared data then multiprocessing provides a couple of ways of doing so.\n",
    "\n",
    "Shared memory\n",
    "\n",
    "Data can be stored in a shared memory map using Value or Array. For example, the following code\n",
    "\n",
    "OR\n",
    "\n",
    "multiprocessing module provides Array and Value objects to share data between processes.\n",
    "\n",
    "    1.Array: a ctypes array allocated from shared memory.\n",
    "    2.Value: a ctypes object allocated from shared memory.\n",
    "            \n",
    "Given below is a simple example showing use of Array and Value for sharing data between processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def f(n, a):\n",
    "    n.value = 3.1415927\n",
    "    for i in range(len(a)):\n",
    "        a[i] = -a[i]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = Value('d', 0.0)\n",
    "    arr = Array('i', range(10))\n",
    "\n",
    "    p = Process(target=f, args=(num, arr))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(num.value)\n",
    "    print(arr[:])\n",
    "\n",
    "#Output will print\n",
    "\n",
    "#3.1415927\n",
    "#[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\n",
    "#The 'd' and 'i' arguments used when creating num and arr are typecodes of the kind used by the array module:#\n",
    "#'d' indicates a double precision float and 'i' indicates a signed integer.\n",
    "#These shared objects will be process and thread-safe.\n",
    "\n",
    "#For more flexibility in using shared memory one can use the multiprocessing.sharedctypes module which \n",
    "#supports the creation of arbitrary ctypes objects allocated from shared memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 . Server process\n",
    "\n",
    "A manager object returned by Manager() controls a server process which holds Python objects and allows other processes to manipulate them using proxies.\n",
    "\n",
    "A manager returned by Manager() will support types list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value and Array. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "\n",
    "def f(d, l):\n",
    "    d[1] = '1'\n",
    "    d['2'] = 2\n",
    "    d[0.25] = None\n",
    "    l.reverse()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Manager() as manager:\n",
    "        d = manager.dict()\n",
    "        l = manager.list(range(10))\n",
    "\n",
    "        p = Process(target=f, args=(d, l))\n",
    "        p.start()\n",
    "        p.join()\n",
    "\n",
    "        print(d)\n",
    "        print(l)\n",
    "        \n",
    "#Output will print\n",
    "\n",
    "#{0.25: None, 1: '1', '2': 2}\n",
    "#[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "#Server process managers are more flexible than using shared memory objects because they can be made to support\n",
    "#arbitrary object types. Also, a single manager can be shared by processes on different computers over a network. \n",
    "#They are, however, slower than using shared memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming guidelines\n",
    "\n",
    "Avoid shared state\n",
    "\n",
    "As far as possible one should try to avoid shifting large amounts of data between processes.\n",
    "\n",
    "It is probably best to stick to using queues or pipes for communication between processes rather than using the lower level synchronization primitives.\n",
    "\n",
    "Picklability\n",
    "\n",
    "Ensure that the arguments to the methods of proxies are picklable.\n",
    "Thread safety of proxies\n",
    "\n",
    "Do not use a proxy object from more than one thread unless you protect it with a lock.\n",
    "\n",
    "(There is never a problem with different processes using the same proxy.)\n",
    "\n",
    "Joining zombie processes\n",
    "\n",
    "On Unix when a process finishes but has not been joined it becomes a zombie. There should never be very many because each time a new process starts (or active_children() is called) all completed processes which have not yet been joined will be joined. Also calling a finished process’s Process.is_alive will join the process. Even so it is probably good practice to explicitly join all the processes that you start.\n",
    "Better to inherit than pickle/unpickle\n",
    "\n",
    "When using the spawn or forkserver start methods many types from multiprocessing need to be picklable so that child processes can use them. However, one should generally avoid sending shared objects to other processes using pipes or queues. Instead you should arrange the program so that a process which needs access to a shared resource created elsewhere can inherit it from an ancestor process.\n",
    "Avoid terminating processes\n",
    "\n",
    "Using the Process.terminate method to stop a process is liable to cause any shared resources (such as locks, semaphores, pipes and queues) currently being used by the process to become broken or unavailable to other processes.\n",
    "\n",
    "Therefore it is probably best to only consider using Process.terminate on processes which never use any shared resources.\n",
    "\n",
    "Joining processes that use queues\n",
    "\n",
    "Bear in mind that a process that has put items in a queue will wait before terminating until all the buffered items are fed by the “feeder” thread to the underlying pipe. (The child process can call the Queue.cancel_join_thread method of the queue to avoid this behaviour.)\n",
    "\n",
    "This means that whenever you use a queue you need to make sure that all items which have been put on the queue will eventually be removed before the process is joined. Otherwise you cannot be sure that processes which have put items on the queue will terminate. Remember also that non-daemonic processes will be joined automatically.\n",
    "\n",
    "An example which will deadlock is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def f(q):\n",
    "    q.put('X' * 1000000)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    queue = Queue()\n",
    "    p = Process(target=f, args=(queue,))\n",
    "    p.start()\n",
    "    p.join()                    # this deadlocks\n",
    "    obj = queue.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and exceptions\n",
    "\n",
    "run()\n",
    "Method representing the process’s activity.\n",
    "\n",
    "You may override this method in a subclass. The standard run() method invokes the callable object passed to the object’s constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively.\n",
    "\n",
    "start()\n",
    "Start the process’s activity.\n",
    "\n",
    "This must be called at most once per process object. It arranges for the object’s run() method to be invoked in a separate process.\n",
    "\n",
    "join([timeout])\n",
    "If the optional argument timeout is None (the default), the method blocks until the process whose join() method is called terminates. If timeout is a positive number, it blocks at most timeout seconds.\n",
    "\n",
    "A process can be joined many times.\n",
    "\n",
    "A process cannot join itself because this would cause a deadlock. It is an error to attempt to join a process before it has been started.\n",
    "\n",
    "name\n",
    "The process’s name. The name is a string used for identification purposes only. It has no semantics. Multiple processes may be given the same name.\n",
    "\n",
    "The initial name is set by the constructor. If no explicit name is provided to the constructor, a name of the form ‘Process-N1:N2:…:Nk’ is constructed, where each Nk is the N-th child of its parent.\n",
    "\n",
    "is_alive()\n",
    "Return whether the process is alive.\n",
    "\n",
    "Roughly, a process object is alive from the moment the start() method returns until the child process terminates.\n",
    "\n",
    "daemon\n",
    "The process’s daemon flag, a Boolean value. This must be set before start() is called.\n",
    "\n",
    "The initial value is inherited from the creating process.\n",
    "\n",
    "When a process exits, it attempts to terminate all of its daemonic child processes.\n",
    "\n",
    "Note that a daemonic process is not allowed to create child processes. Otherwise a daemonic process would leave its children orphaned if it gets terminated when its parent process exits. Additionally, these are not Unix daemons or services, they are normal processes that will be terminated (and not joined) if non-daemonic processes have exited.\n",
    "\n",
    "pid\n",
    "Return the process ID. Before the process is spawned, this will be None.\n",
    "\n",
    "\n",
    "Note that the start(), join(), is_alive(), terminate() and exitcode methods should only be called by the process that created the process object.\n",
    "\n",
    "Example usage of some of the methods of Process:\n",
    "\n",
    ">>> import multiprocessing, time, signal\n",
    ">>> p = multiprocessing.Process(target=time.sleep, args=(1000,))\n",
    ">>> print(p, p.is_alive())\n",
    "<Process(Process-1, initial)> False\n",
    ">>> p.start()\n",
    ">>> print(p, p.is_alive())\n",
    "<Process(Process-1, started)> True\n",
    ">>> p.terminate()\n",
    ">>> time.sleep(0.1)\n",
    ">>> print(p, p.is_alive())\n",
    "<Process(Process-1, stopped[SIGTERM])> False\n",
    ">>> p.exitcode == -signal.SIGTERM\n",
    "True\n",
    "\n",
    "\n",
    "poll([timeout])\n",
    "Return whether there is any data available to be read.\n",
    "\n",
    "If timeout is not specified then it will return immediately. If timeout is a number then this specifies the maximum time in seconds to block. If timeout is None then an infinite timeout is used.\n",
    "\n",
    "Note that multiple connection objects may be polled at once by using multiprocessing.connection.wait().\n",
    "\n",
    "\n",
    "\n",
    "class multiprocessing.Lock\n",
    "A non-recursive lock object: a close analog of threading.Lock. Once a process or thread has acquired a lock, subsequent attempts to acquire it from any process or thread will block until it is released; any process or thread may release it. The concepts and behaviors of threading.Lock as it applies to threads are replicated here in multiprocessing.Lock as it applies to either processes or threads, except as noted.\n",
    "\n",
    "Note that Lock is actually a factory function which returns an instance of multiprocessing.synchronize.Lock initialized with a default context.\n",
    "\n",
    "Lock supports the context manager protocol and thus may be used in with statements.\n",
    "\n",
    "acquire(block=True, timeout=None)\n",
    "Acquire a lock, blocking or non-blocking.\n",
    "\n",
    "With the block argument set to True (the default), the method call will block until the lock is in an unlocked state, then set it to locked and return True. Note that the name of this first argument differs from that in threading.Lock.acquire().\n",
    "\n",
    "With the block argument set to False, the method call does not block. If the lock is currently in a locked state, return False; otherwise set the lock to a locked state and return True.\n",
    "\n",
    "When invoked with a positive, floating-point value for timeout, block for at most the number of seconds specified by timeout as long as the lock can not be acquired. Invocations with a negative value for timeout are equivalent to a timeout of zero. Invocations with a timeout value of None (the default) set the timeout period to infinite. Note that the treatment of negative or None values for timeout differs from the implemented behavior in threading.Lock.acquire(). The timeout argument has no practical implications if the block argument is set to False and is thus ignored. Returns True if the lock has been acquired or False if the timeout period has elapsed.\n",
    "\n",
    "release()\n",
    "Release a lock. This can be called from any process or thread, not only the process or thread which originally acquired the lock.\n",
    "\n",
    "Behavior is the same as in threading.Lock.release() except that when invoked on an unlocked lock, a ValueError is raised.\n",
    "\n",
    "class multiprocessing.RLock\n",
    "A recursive lock object: a close analog of threading.RLock. A recursive lock must be released by the process or thread that acquired it. Once a process or thread has acquired a recursive lock, the same process or thread may acquire it again without blocking; that process or thread must release it once for each time it has been acquired.\n",
    "\n",
    "Note that RLock is actually a factory function which returns an instance of multiprocessing.synchronize.RLock initialized with a default context.\n",
    "\n",
    "RLock supports the context manager protocol and thus may be used in with statements.\n",
    "\n",
    "acquire(block=True, timeout=None)\n",
    "Acquire a lock, blocking or non-blocking.\n",
    "\n",
    "When invoked with the block argument set to True, block until the lock is in an unlocked state (not owned by any process or thread) unless the lock is already owned by the current process or thread. The current process or thread then takes ownership of the lock (if it does not already have ownership) and the recursion level inside the lock increments by one, resulting in a return value of True. Note that there are several differences in this first argument’s behavior compared to the implementation of threading.RLock.acquire(), starting with the name of the argument itself.\n",
    "\n",
    "When invoked with the block argument set to False, do not block. If the lock has already been acquired (and thus is owned) by another process or thread, the current process or thread does not take ownership and the recursion level within the lock is not changed, resulting in a return value of False. If the lock is in an unlocked state, the current process or thread takes ownership and the recursion level is incremented, resulting in a return value of True.\n",
    "\n",
    "Use and behaviors of the timeout argument are the same as in Lock.acquire(). Note that some of these behaviors of timeout differ from the implemented behaviors in threading.RLock.acquire().\n",
    "\n",
    "release()\n",
    "Release a lock, decrementing the recursion level. If after the decrement the recursion level is zero, reset the lock to unlocked (not owned by any process or thread) and if any other processes or threads are blocked waiting for the lock to become unlocked, allow exactly one of them to proceed. If after the decrement the recursion level is still nonzero, the lock remains locked and owned by the calling process or thread.\n",
    "\n",
    "Only call this method when the calling process or thread owns the lock. An AssertionError is raised if this method is called by a process or thread other than the owner or if the lock is in an unlocked (unowned) state. Note that the type of exception raised in this situation differs from the implemented behavior in threading.RLock.release().\n",
    "\n",
    "class multiprocessing.Semaphore([value])\n",
    "A semaphore object: a close analog of threading.Semaphore.\n",
    "\n",
    "A solitary difference from its close analog exists: its acquire method’s first argument is named block, as is consistent with Lock.acquire()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicitly pass resources to child processes\n",
    "\n",
    "On Unix using the fork start method, a child process can make use of a shared resource created in a parent process using a global resource. However, it is better to pass the object as an argument to the constructor for the child process.\n",
    "\n",
    "Apart from making the code (potentially) compatible with Windows and the other start methods this also ensures that as long as the child process is still alive the object will not be garbage collected in the parent process. This might be important if some resource is freed when the object is garbage collected in the parent process.\n",
    "\n",
    "So for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Lock\n",
    "\n",
    "def f():\n",
    "    ... do something using \"lock\" ...\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   lock = Lock()\n",
    "   for i in range(10):\n",
    "        Process(target=f).start()\n",
    "should be rewritten as\n",
    "\n",
    "from multiprocessing import Process, Lock\n",
    "\n",
    "def f(l):\n",
    "    ... do something using \"l\" ...\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   lock = Lock()\n",
    "   for i in range(10):\n",
    "        Process(target=f, args=(lock,)).start()\n",
    "        \n",
    "Beware of replacing sys.stdin with a “file like object”\n",
    "\n",
    "multiprocessing originally unconditionally called:\n",
    "\n",
    "os.close(sys.stdin.fileno())\n",
    "in the multiprocessing.Process._bootstrap() method — this resulted in issues with processes-in-processes. \n",
    "This has been changed to:\n",
    "\n",
    "sys.stdin.close()\n",
    "sys.stdin = open(os.devnull)\n",
    "Which solves the fundamental issue of processes colliding with each other resulting in a bad file descriptor error, \n",
    "but introduces a potential danger to applications which replace sys.stdin() with a “file-like object” with output buffering.\n",
    "This danger is that if multiple processes call close() on this file-like object, it could result in the same data being flushed\n",
    "to the object multiple times, resulting in corruption.\n",
    "\n",
    "If you write a file-like object and implement your own caching, you can make it fork-safe by storing the pid whenever you \n",
    "append to the cache, and discarding the cache when the pid changes. For example:\n",
    "\n",
    "@property\n",
    "def cache(self):\n",
    "    pid = os.getpid()\n",
    "    if pid != self._pid:\n",
    "        self._pid = pid\n",
    "        self._cache = []\n",
    "    return self._cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "Demonstration of how to create and use customized managers and proxies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import freeze_support\n",
    "from multiprocessing.managers import BaseManager, BaseProxy\n",
    "import operator\n",
    "\n",
    "##\n",
    "\n",
    "class Foo:\n",
    "    def f(self):\n",
    "        print('you called Foo.f()')\n",
    "    def g(self):\n",
    "        print('you called Foo.g()')\n",
    "    def _h(self):\n",
    "        print('you called Foo._h()')\n",
    "\n",
    "# A simple generator function\n",
    "def baz():\n",
    "    for i in range(10):\n",
    "        yield i*i\n",
    "\n",
    "# Proxy type for generator objects\n",
    "class GeneratorProxy(BaseProxy):\n",
    "    _exposed_ = ['__next__']\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        return self._callmethod('__next__')\n",
    "\n",
    "# Function to return the operator module\n",
    "def get_operator_module():\n",
    "    return operator\n",
    "\n",
    "##\n",
    "\n",
    "class MyManager(BaseManager):\n",
    "    pass\n",
    "\n",
    "# register the Foo class; make `f()` and `g()` accessible via proxy\n",
    "MyManager.register('Foo1', Foo)\n",
    "\n",
    "# register the Foo class; make `g()` and `_h()` accessible via proxy\n",
    "MyManager.register('Foo2', Foo, exposed=('g', '_h'))\n",
    "\n",
    "# register the generator function baz; use `GeneratorProxy` to make proxies\n",
    "MyManager.register('baz', baz, proxytype=GeneratorProxy)\n",
    "\n",
    "# register get_operator_module(); make public functions accessible via proxy\n",
    "MyManager.register('operator', get_operator_module)\n",
    "\n",
    "##\n",
    "\n",
    "def test():\n",
    "    manager = MyManager()\n",
    "    manager.start()\n",
    "\n",
    "    print('-' * 20)\n",
    "\n",
    "    f1 = manager.Foo1()\n",
    "    f1.f()\n",
    "    f1.g()\n",
    "    assert not hasattr(f1, '_h')\n",
    "    assert sorted(f1._exposed_) == sorted(['f', 'g'])\n",
    "\n",
    "    print('-' * 20)\n",
    "\n",
    "    f2 = manager.Foo2()\n",
    "    f2.g()\n",
    "    f2._h()\n",
    "    assert not hasattr(f2, 'f')\n",
    "    assert sorted(f2._exposed_) == sorted(['g', '_h'])\n",
    "\n",
    "    print('-' * 20)\n",
    "\n",
    "    it = manager.baz()\n",
    "    for i in it:\n",
    "        print('<%d>' % i, end=' ')\n",
    "    print()\n",
    "\n",
    "    print('-' * 20)\n",
    "\n",
    "    op = manager.operator()\n",
    "    print('op.add(23, 45) =', op.add(23, 45))\n",
    "    print('op.pow(2, 94) =', op.pow(2, 94))\n",
    "    print('op._exposed_ =', op._exposed_)\n",
    "\n",
    "##\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    freeze_support()\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######    Using Pool:\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "\n",
    "#\n",
    "# Functions used by test code\n",
    "#\n",
    "\n",
    "def calculate(func, args):\n",
    "    result = func(*args)\n",
    "    return '%s says that %s%s = %s' % (\n",
    "        multiprocessing.current_process().name,\n",
    "        func.__name__, args, result\n",
    "        )\n",
    "\n",
    "def calculatestar(args):\n",
    "    return calculate(*args)\n",
    "\n",
    "def mul(a, b):\n",
    "    time.sleep(0.5 * random.random())\n",
    "    return a * b\n",
    "\n",
    "def plus(a, b):\n",
    "    time.sleep(0.5 * random.random())\n",
    "    return a + b\n",
    "\n",
    "def f(x):\n",
    "    return 1.0 / (x - 5.0)\n",
    "\n",
    "def pow3(x):\n",
    "    return x ** 3\n",
    "\n",
    "def noop(x):\n",
    "    pass\n",
    "\n",
    "#\n",
    "# Test code\n",
    "#\n",
    "\n",
    "def test():\n",
    "    PROCESSES = 4\n",
    "    print('Creating pool with %d processes\\n' % PROCESSES)\n",
    "\n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        #\n",
    "        # Tests\n",
    "        #\n",
    "\n",
    "        TASKS = [(mul, (i, 7)) for i in range(10)] + \\\n",
    "                [(plus, (i, 8)) for i in range(10)]\n",
    "\n",
    "        results = [pool.apply_async(calculate, t) for t in TASKS]\n",
    "        imap_it = pool.imap(calculatestar, TASKS)\n",
    "        imap_unordered_it = pool.imap_unordered(calculatestar, TASKS)\n",
    "\n",
    "        print('Ordered results using pool.apply_async():')\n",
    "        for r in results:\n",
    "            print('\\t', r.get())\n",
    "        print()\n",
    "\n",
    "        print('Ordered results using pool.imap():')\n",
    "        for x in imap_it:\n",
    "            print('\\t', x)\n",
    "        print()\n",
    "\n",
    "        print('Unordered results using pool.imap_unordered():')\n",
    "        for x in imap_unordered_it:\n",
    "            print('\\t', x)\n",
    "        print()\n",
    "\n",
    "        print('Ordered results using pool.map() --- will block till complete:')\n",
    "        for x in pool.map(calculatestar, TASKS):\n",
    "            print('\\t', x)\n",
    "        print()\n",
    "\n",
    "        #\n",
    "        # Test error handling\n",
    "        #\n",
    "\n",
    "        print('Testing error handling:')\n",
    "\n",
    "        try:\n",
    "            print(pool.apply(f, (5,)))\n",
    "        except ZeroDivisionError:\n",
    "            print('\\tGot ZeroDivisionError as expected from pool.apply()')\n",
    "        else:\n",
    "            raise AssertionError('expected ZeroDivisionError')\n",
    "\n",
    "        try:\n",
    "            print(pool.map(f, list(range(10))))\n",
    "        except ZeroDivisionError:\n",
    "            print('\\tGot ZeroDivisionError as expected from pool.map()')\n",
    "        else:\n",
    "            raise AssertionError('expected ZeroDivisionError')\n",
    "\n",
    "        try:\n",
    "            print(list(pool.imap(f, list(range(10)))))\n",
    "        except ZeroDivisionError:\n",
    "            print('\\tGot ZeroDivisionError as expected from list(pool.imap())')\n",
    "        else:\n",
    "            raise AssertionError('expected ZeroDivisionError')\n",
    "\n",
    "        it = pool.imap(f, list(range(10)))\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                x = next(it)\n",
    "            except ZeroDivisionError:\n",
    "                if i == 5:\n",
    "                    pass\n",
    "            except StopIteration:\n",
    "                break\n",
    "            else:\n",
    "                if i == 5:\n",
    "                    raise AssertionError('expected ZeroDivisionError')\n",
    "\n",
    "        assert i == 9\n",
    "        print('\\tGot ZeroDivisionError as expected from IMapIterator.next()')\n",
    "        print()\n",
    "\n",
    "        #\n",
    "        # Testing timeouts\n",
    "        #\n",
    "\n",
    "        print('Testing ApplyResult.get() with timeout:', end=' ')\n",
    "        res = pool.apply_async(calculate, TASKS[0])\n",
    "        while 1:\n",
    "            sys.stdout.flush()\n",
    "            try:\n",
    "                sys.stdout.write('\\n\\t%s' % res.get(0.02))\n",
    "                break\n",
    "            except multiprocessing.TimeoutError:\n",
    "                sys.stdout.write('.')\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "        print('Testing IMapIterator.next() with timeout:', end=' ')\n",
    "        it = pool.imap(calculatestar, TASKS)\n",
    "        while 1:\n",
    "            sys.stdout.flush()\n",
    "            try:\n",
    "                sys.stdout.write('\\n\\t%s' % it.next(0.02))\n",
    "            except StopIteration:\n",
    "                break\n",
    "            except multiprocessing.TimeoutError:\n",
    "                sys.stdout.write('.')\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "    test()\n",
    "An example showing how to use queues to feed tasks to a collection of worker processes and collect the results:\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from multiprocessing import Process, Queue, current_process, freeze_support\n",
    "\n",
    "#\n",
    "# Function run by worker processes\n",
    "#\n",
    "\n",
    "def worker(input, output):\n",
    "    for func, args in iter(input.get, 'STOP'):\n",
    "        result = calculate(func, args)\n",
    "        output.put(result)\n",
    "\n",
    "#\n",
    "# Function used to calculate result\n",
    "#\n",
    "\n",
    "def calculate(func, args):\n",
    "    result = func(*args)\n",
    "    return '%s says that %s%s = %s' % \\\n",
    "        (current_process().name, func.__name__, args, result)\n",
    "\n",
    "#\n",
    "# Functions referenced by tasks\n",
    "#\n",
    "\n",
    "def mul(a, b):\n",
    "    time.sleep(0.5*random.random())\n",
    "    return a * b\n",
    "\n",
    "def plus(a, b):\n",
    "    time.sleep(0.5*random.random())\n",
    "    return a + b\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "def test():\n",
    "    NUMBER_OF_PROCESSES = 4\n",
    "    TASKS1 = [(mul, (i, 7)) for i in range(20)]\n",
    "    TASKS2 = [(plus, (i, 8)) for i in range(10)]\n",
    "\n",
    "    # Create queues\n",
    "    task_queue = Queue()\n",
    "    done_queue = Queue()\n",
    "\n",
    "    # Submit tasks\n",
    "    for task in TASKS1:\n",
    "        task_queue.put(task)\n",
    "\n",
    "    # Start worker processes\n",
    "    for i in range(NUMBER_OF_PROCESSES):\n",
    "        Process(target=worker, args=(task_queue, done_queue)).start()\n",
    "\n",
    "    # Get and print results\n",
    "    print('Unordered results:')\n",
    "    for i in range(len(TASKS1)):\n",
    "        print('\\t', done_queue.get())\n",
    "\n",
    "    # Add more tasks using `put()`\n",
    "    for task in TASKS2:\n",
    "        task_queue.put(task)\n",
    "\n",
    "    # Get and print some more results\n",
    "    for i in range(len(TASKS2)):\n",
    "        print('\\t', done_queue.get())\n",
    "\n",
    "    # Tell child processes to stop\n",
    "    for i in range(NUMBER_OF_PROCESSES):\n",
    "        task_queue.put('STOP')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    freeze_support()\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
